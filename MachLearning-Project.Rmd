---
title: 'Practical Machine Learning: Project Report'
author: "Alexander Zhou"
date: "12/19/2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, keep_md, fig.path = "./figures/")
require(caret)
require(corrplot)
require(rpart.plot)
require(stats)
require(doMC)
registerDoMC(cores = 8)
set.seed(2501)
```

## Background

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. The goal of this project is to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants who were asked to perform barbell lifts correctly and incorrectly in 5 different ways, represented as classes in the training set. 

## Data Processing

Downloading files as needed and loading them into the workspace
```{r download, cache = TRUE}
if (!file.exists("pml-training.csv")) { 
  download.file(
    "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", 
    "pml-training.csv")
}
if (!file.exists("pml-testing.csv")) { 
  download.file(
    "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", 
    "pml-testing.csv")
}

train = read.csv("pml-training.csv", sep = ",", na.strings=c("NA", "#DIV/0!",""))
test = read.csv("pml-testing.csv", sep = ",", na.strings=c("NA", "#DIV/0!",""))

dim(train)
dim(test)
```

## Data Cleanup
Remove observation with mission values and reduce data set size by dropping not used variables. Finally slice the training set into a training (70%) and cross validation (30%) part. 
```{r cleanup, cache = TRUE}
naNameRatio.train <- sapply(train, function(x) {sum(is.na(x) == TRUE) / length(x)})
naNameRatio.test <- sapply(test, function(x) {sum(is.na(x) == TRUE) / length(x)})

train <- train[,names(which(naNameRatio.train < 0.95))]
test <- test[,names(which(naNameRatio.test < 0.95))]

train.clean <- train[,!grepl("X|timestamp|user_name|window", names(train))]
test.clean <- test[,!grepl("X|timestamp|user_name|window", names(test))]

index.train <- createDataPartition(train.clean$classe, p=0.70, list = FALSE)
train.data <- train.clean[index.train , ]
train.cross <- train.clean[-index.train , ]
```

## Training Random Forest

Random Forest training with 5-fold cross validation similar to the one used by the researchers of the original study. 
```{r training, cache = TRUE}
control.rf <- trainControl(method = "cv", classProbs = TRUE, savePredictions = TRUE,
                           allowParallel = TRUE, number = 10)
model.rf <- train(classe ~ ., data = train.data, method = "rf", trControl = control.rf)
```

## Model Validation

The model performance is measured against the cross validation data set.
```{r validation, cache = TRUE}
cross.rf <- predict(model.rf, train.cross)
confusionMatrix(train.cross$classe, cross.rf)
postResample(cross.rf, train.cross$classe)
```

## Model Predictions

The fitted model is now being used to predict the test data, in order to answer the project quiz.
```{r predictions, cache = TRUE}
predict(model.rf, newdata = test.clean)
```

## Appendix 

### 1. Variable Importance Visualization
```{r importance, cache = TRUE}
print(plot(varImp(model.rf, scale = FALSE)))
```

### 3. Correlation Matrix Visualization
```{r corr-matrix, cache = TRUE}
corrplot(cor(train.data[, -length(names(train.data))]), method="color")
```

### 3. Decision Tree Visualization
```{r tree, cache = TRUE}
prp(rpart(classe ~ ., data=train.data, method="class"))
```

### 4. Error Rate Visualization
```{r error, cache = TRUE}
plot(model.rf$finalModel, main = "Random Tree Model Error Rate")
```

### 5. Session Info
```{r session}
sessionInfo()
```
